<!DOCTYPE html>
<html lang="ko"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>최적화 · 🦉</title><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-6977995344550016",
          enable_page_level_ads: true
     });
</script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link href="../../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../../assets/custom.css" rel="stylesheet" type="text/css"/><script src="assets/jquery-1.8.3.min.js"></script><script src="assets/jquery.word-break-keep-all.min.js"></script><script>$(document).ready(function() { $('p').wordBreakKeepAll(); });</script></head><body><nav class="toc"><h1>🦉</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../../">Home</a></li><li><span class="toctext">Flux ✅</span><ul><li><a class="toctext" href="../../">Flux 홈</a></li><li><span class="toctext">모델 만들기</span><ul><li><a class="toctext" href="../../models/basics/">기본적인 것</a></li><li><a class="toctext" href="../../models/recurrence/">순환(Recurrence)</a></li><li><a class="toctext" href="../../models/regularisation/">정규화(Regularisation)</a></li><li><a class="toctext" href="../../models/layers/">모델 참조(Model Reference)</a></li></ul></li><li><span class="toctext">모델 훈련시키기</span><ul><li class="current"><a class="toctext" href>최적화</a><ul class="internal"><li><a class="toctext" href="#최적화-함수-참고-1">최적화 함수 참고</a></li></ul></li><li><a class="toctext" href="../training/">훈련시키기</a></li></ul></li><li><a class="toctext" href="../../data/onehot/">원-핫 인코딩</a></li><li><a class="toctext" href="../../gpu/">GPU 지원</a></li><li><a class="toctext" href="../../saving/">저장 &amp; 불러오기</a></li><li><a class="toctext" href="../../community/">커뮤니티</a></li></ul></li><li><span class="toctext">DataFlow ✅</span><ul><li><a class="toctext" href="../../../DataFlow/vertices/">DataFlow 버티스(vertices)</a></li></ul></li><li><span class="toctext">MacroTools</span><ul><li><a class="toctext" href="../../../MacroTools/README/">MacroTools README</a></li></ul></li><li><span class="toctext">FluxJS</span><ul><li><a class="toctext" href="../../../FluxJS/README/">FluxJS README</a></li></ul></li><li><span class="toctext">Vinyl</span><ul><li><a class="toctext" href="../../../Vinyl/README/">Vinyl README</a></li></ul></li><li><span class="toctext">GSoC</span><ul><li><a class="toctext" href="../../../soc/guidelines/">Application Guidelines</a></li><li><a class="toctext" href="../../../soc/projects/ml/">Data Science &amp; Machine Learning</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Flux ✅</li><li>모델 훈련시키기</li><li><a href>최적화</a></li></ul><a class="edit-page" href="https://github.com/wookay/Owl.jl/blob/master/docs/src/Flux/training/optimisers.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>최적화</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="최적화-함수(Optimisers)-1" href="#최적화-함수(Optimisers)-1">최적화 함수(Optimisers)</a></h1><p><a href="../../models/basics/">간단한 리니어 리그레션</a>에서 우리는 더미 데이터를 만든 후, 손실(loss)을 계산하고 역전파(backpropagate) 하여 파라미터 <code>W</code>와 <code>b</code>의 기울기를 계산하였다.</p><pre><code class="language-julia-repl">julia&gt; using Flux

julia&gt; W = param(rand(2, 5))
Tracked 2×5 Array{Float64,2}:
 0.215021  0.22422   0.352664  0.11115   0.040711
 0.180933  0.769257  0.361652  0.783197  0.545495

julia&gt; b = param(rand(2))
Tracked 2-element Array{Float64,1}:
 0.205216
 0.150938

julia&gt; predict(x) = W*x .+ b
predict (generic function with 1 method)

julia&gt; loss(x, y) = sum((predict(x) .- y).^2)
loss (generic function with 1 method)

julia&gt; x, y = rand(5), rand(2) # 더미 데이터
([0.153473, 0.927019, 0.40597, 0.783872, 0.392236], [0.261727, 0.00917161])

julia&gt; l = loss(x, y) # ~ 3
3.6352060699201565 (tracked)

julia&gt; Flux.back!(l)
</code></pre><p>기울기를 사용하여 파라미터를 업데이트 하고자 한다. 손실을 줄이려고 말이다. 여기서 한가지 방법은:</p><pre><code class="language-julia">function update()
  η = 0.1 # 학습하는 속도(Learning Rate)
  for p in (W, b)
    p.data .-= η .* p.grad # 업데이트 적용
    p.grad .= 0            # 기울기 0으로 clear
  end
end</code></pre><p><code>update</code>를 호출하면 파라미터 <code>W</code>와 <code>b</code>는 바뀌고 손실(loss)은 내려간다.</p><p>두가지는 짚고 넘어가자: 모델에서 훈련할 파라미터의 목록 (여기서는 <code>[W, b]</code>), 그리고 업데이트 진행 속도. 여기서의 업데이트는 간단한 gradient descent(경사 하강, <code>x .-= η .* Δ</code>) 였지만, 모멘텀(momentum)을 추가하는 것처럼 보다 어려운 것도 해보고 싶을 것이다.</p><p>여기서 변수를 얻는 것은 아무것도 아니지만, 레이어를 복잡하게 쌓는다면 골치 좀 아플 것이다.</p><pre><code class="language-julia-repl">julia&gt; m = Chain(
         Dense(10, 5, σ),
         Dense(5, 2), softmax)
Chain(Dense(10, 5, NNlib.σ), Dense(5, 2), NNlib.softmax)</code></pre><p><code>[m[1].W, m[1].b, ...]</code> 이렇게 작성하는 것 대신, Flux에서 제공하는 <code>params(m)</code> 함수를 이용해 모델의 모든 파라미터의 목록을 구할 것이다.</p><pre><code class="language-julia-repl">julia&gt; opt = SGD([W, b], 0.1) # Gradient descent(경사 하강)을 learning rate(학습 속도) 0.1 으로 한다
(::#71) (generic function with 1 method)

julia&gt; opt() # `W`와 `b`를 변경하며 업데이트를 수행한다
</code></pre><p>최적화 함수는 파라미터 목록을 받아 위의 <code>update</code>와 같은 함수를 돌려준다. <code>opt</code>나 <code>update</code>를 <a href="../training/">훈련 루프(training loop)</a>에 넘겨줄 수 있는데, 매번 데이터의 미니-배치(mini-batch)를 한 후에 최적화를 수행할 것이다.</p><h2><a class="nav-anchor" id="최적화-함수-참고-1" href="#최적화-함수-참고-1">최적화 함수 참고</a></h2><p>모든 최적화 함수는 넘겨받은 파라미터를 업데이트 하는 함수를 돌려준다.</p><pre><code class="language-none">SGD
Momentum
Nesterov
ADAM</code></pre><footer><hr/><a class="previous" href="../../models/layers/"><span class="direction">이전글</span><span class="title">모델 참조(Model Reference)</span></a><a class="next" href="../training/"><span class="direction">다음글</span><span class="title">훈련시키기</span></a></footer></article></body></html>
