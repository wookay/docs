<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training · 🦉</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>🦉</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../index.html">Home</a></li><li><span class="toctext">Flux</span><ul><li><a class="toctext" href="../index.html">Flux 홈</a></li><li><span class="toctext">모델 만들기</span><ul><li><a class="toctext" href="../models/basics.html">기본적인 것</a></li><li><a class="toctext" href="../models/recurrence.html">순환(Recurrence)</a></li><li><a class="toctext" href="../models/regularisation.html">정규화(Regularisation)</a></li><li><a class="toctext" href="../models/layers.html">모델 참조(Model Reference)</a></li></ul></li><li><span class="toctext">Training Models</span><ul><li><a class="toctext" href="optimisers.html">Optimisers</a></li><li class="current"><a class="toctext" href="training.html">Training</a><ul class="internal"><li><a class="toctext" href="#손실-함수(Loss-Functions)-1">손실 함수(Loss Functions)</a></li><li><a class="toctext" href="#데이터세트(Datasets)-1">데이터세트(Datasets)</a></li><li><a class="toctext" href="#Callbacks-1">Callbacks</a></li></ul></li></ul></li><li><a class="toctext" href="../data/onehot.html">One-Hot Encoding</a></li><li><a class="toctext" href="../gpu.html">GPU Support</a></li><li><a class="toctext" href="../saving.html">Saving &amp; Loading</a></li><li><a class="toctext" href="../community.html">Community</a></li></ul></li><li><span class="toctext">GSoC</span><ul><li><a class="toctext" href="../../soc/guidelines/index.html">Application Guidelines</a></li><li><a class="toctext" href="../../soc/projects/ml.html">Data Science &amp; Machine Learning</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Flux</li><li>Training Models</li><li><a href="training.html">Training</a></li></ul><a class="edit-page" href="https://github.com/wookay/Owl.jl/blob/master/docs/src/Flux/training/training.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Training</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="훈련하기(Training)-1" href="#훈련하기(Training)-1">훈련하기(Training)</a></h1><p>모델을 훈련하려면 세가지가 필요하다:</p><ul><li><p><em>목표 함수(objective function)</em>, 주어진 데이터를 얼만큼 잘 평가할 것인가.</p></li><li><p>데이터 포인트(A collection of data points)를 목표 함수에 넘겨줄 것이다.</p></li><li><p><a href="optimisers.html">최적화 함수</a>로 모델 파라미터를 적절하게 업데이트 할 것이다.</p></li></ul><p>그리하여 <code>Flux.train!</code>는 다음과 같이 호출한다:</p><pre><code class="language-julia">Flux.train!(objective, data, opt)</code></pre><p><a href="https://github.com/FluxML/model-zoo">모델 동물원(model zoo)</a>에 여러가지 예제가 있다.</p><h2><a class="nav-anchor" id="손실-함수(Loss-Functions)-1" href="#손실-함수(Loss-Functions)-1">손실 함수(Loss Functions)</a></h2><p>목표 함수는 반드시 모델과 대상(target)의 차이를 나타내는 숫자를 돌려주어야 한다 - 모델의 <em>loss</em>. <a href="../models/basics.html">기초</a>에서 정의한 <code>loss</code> 함수가 목표(an objective)로서 작동할 것이다. 모델의 관점에서 목표를 정의할 수도 있다:</p><pre><code class="language-julia-repl">julia&gt; using Flux

julia&gt; m = Chain(
         Dense(784, 32, σ),
         Dense(32, 10), softmax)
Chain(Dense(784, 32, NNlib.σ), Dense(32, 10), NNlib.softmax)

julia&gt; loss(x, y) = Flux.mse(m(x), y)
loss (generic function with 1 method)

# 나중에
julia&gt; Flux.train!(loss, data, opt)</code></pre><p>목표는 항상 <code>m(x)</code>의 예측과 대상 <code>y</code>의 거리를 측정하는 <em>비용 함수(cost function)</em>의 관점에서 정의된다. Flux는 mean squared error를 구하는 <code>mse</code>나, cross entropy loss를 구하는 <code>crossentropy</code> 같은 비용 함수를 내장하고 있다. 원한다면 직접 계산해 볼 수도 있다.</p><h2><a class="nav-anchor" id="데이터세트(Datasets)-1" href="#데이터세트(Datasets)-1">데이터세트(Datasets)</a></h2><p><code>data</code>  The <code>data</code> argument provides a collection of data to train with (usually a set of inputs <code>x</code> and target outputs <code>y</code>). For example, here&#39;s a dummy data set with only one data point:</p><pre><code class="language-julia">x = rand(784)
y = rand(10)
data = [(x, y)]</code></pre><p><code>Flux.train!</code> will call <code>loss(x, y)</code>, calculate gradients, update the weights and then move on to the next data point if there is one. We can train the model on the same data three times:</p><pre><code class="language-julia">data = [(x, y), (x, y), (x, y)]
# Or equivalently
data = Iterators.repeated((x, y), 3)</code></pre><p>It&#39;s common to load the <code>x</code>s and <code>y</code>s separately. In this case you can use <code>zip</code>:</p><pre><code class="language-julia">xs = [rand(784), rand(784), rand(784)]
ys = [rand( 10), rand( 10), rand( 10)]
data = zip(xs, ys)</code></pre><p>Note that, by default, <code>train!</code> only loops over the data once (a single &quot;epoch&quot;). A convenient way to run multiple epochs from the REPL is provided by <code>@epochs</code>.</p><pre><code class="language-julia">julia&gt; using Flux: @epochs

julia&gt; @epochs 2 println(&quot;hello&quot;)
INFO: Epoch 1
hello
INFO: Epoch 2
hello

julia&gt; @epochs 2 Flux.train!(...)
# Train for two epochs</code></pre><h2><a class="nav-anchor" id="Callbacks-1" href="#Callbacks-1">Callbacks</a></h2><p><code>train!</code> takes an additional argument, <code>cb</code>, that&#39;s used for callbacks so that you can observe the training process. For example:</p><pre><code class="language-julia">train!(objective, data, opt, cb = () -&gt; println(&quot;training&quot;))</code></pre><p>Callbacks are called for every batch of training data. You can slow this down using <code>Flux.throttle(f, timeout)</code> which prevents <code>f</code> from being called more than once every <code>timeout</code> seconds.</p><p>A more typical callback might look like this:</p><pre><code class="language-julia">test_x, test_y = # ... create single batch of test data ...
evalcb() = @show(loss(test_x, test_y))

Flux.train!(objective, data, opt,
            cb = throttle(evalcb, 5))</code></pre><footer><hr/><a class="previous" href="optimisers.html"><span class="direction">Previous</span><span class="title">Optimisers</span></a><a class="next" href="../data/onehot.html"><span class="direction">Next</span><span class="title">One-Hot Encoding</span></a></footer></article></body></html>
